{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets debug bigbird\n",
    "\n",
    "# vocab is same as roberta/gpt2\n",
    "# for running `sumulated_sparse`, encoder_max seqlen must be 4096\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigbird.core import modeling\n",
    "from bigbird.core import utils\n",
    "\n",
    "from transformers import BigBirdForPreTraining, BigBirdConfig\n",
    "\n",
    "import tensorflow.compat.v2 as tf\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "tf.enable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_CKPT_DIR = \"ckpt/bigbr_base/model.ckpt-0\"\n",
    "HF_CKPT_DIR = \"google/bigbird-base/pytorch_model.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigbird_config = {\n",
    "      # transformer basic configs\n",
    "      \"vocab_size\": 50358,\n",
    "      \"attention_probs_dropout_prob\": 0.1,\n",
    "      \"hidden_act\": \"gelu\",\n",
    "      \"hidden_dropout_prob\": 0.1,\n",
    "      \"hidden_size\": 768,\n",
    "      \"initializer_range\": 0.02,\n",
    "      \"intermediate_size\": 3072,\n",
    "      \"max_position_embeddings\": 4096,\n",
    "      \"num_attention_heads\": 12,\n",
    "      \"num_hidden_layers\": 12,\n",
    "      \"type_vocab_size\": 2,\n",
    "      \"use_bias\": True,\n",
    "      \"rescale_embedding\": False,\n",
    "      \"scope\": \"bert\",\n",
    "      # sparse mask configs\n",
    "      \"attention_type\": \"block_sparse\", # \"block_sparse\" \"original_full\" \"simulated_sparse\"\n",
    "      \"norm_type\": \"postnorm\",\n",
    "      \"block_size\": 16,\n",
    "      \"num_rand_blocks\": 3,\n",
    "      # common bert configs\n",
    "      \"max_encoder_length\": 128,\n",
    "      \"batch_size\": 2,\n",
    "}\n",
    "\n",
    "hf_bigbird_config = BigBirdConfig.from_dict(bigbird_config)\n",
    "hf_bigbird_config.hidden_act = \"gelu_fast\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.compat.v1.set_random_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "s1 = bigbird_config[\"batch_size\"]\n",
    "s2 = bigbird_config[\"max_encoder_length\"]\n",
    "\n",
    "arr = np.random.randint(1, s2, size=s1*s2).reshape(s1, s2)\n",
    "\n",
    "input_ids = tf.convert_to_tensor(arr, dtype=tf.int32)\n",
    "hf_input_ids = torch.from_numpy(arr).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:**** Using original full attention ****\n",
      "INFO:absl:**** Using original full attention ****\n",
      "INFO:absl:**** Using original full attention ****\n",
      "INFO:absl:**** Using original full attention ****\n",
      "INFO:absl:**** Using original full attention ****\n",
      "INFO:absl:**** Using original full attention ****\n",
      "INFO:absl:**** Using original full attention ****\n",
      "INFO:absl:**** Using original full attention ****\n",
      "INFO:absl:**** Using original full attention ****\n",
      "INFO:absl:**** Using original full attention ****\n",
      "INFO:absl:**** Using original full attention ****\n",
      "INFO:absl:**** Using original full attention ****\n"
     ]
    }
   ],
   "source": [
    "model = modeling.BertModel(bigbird_config)\n",
    "_, _ = model(input_ids, training=False) # building all the weights before setting-up :)\n",
    "\n",
    "hf_model = BigBirdForPreTraining(hf_bigbird_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 199/199 [00:00<00:00, 344.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model weights loaded'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_reader = tf.compat.v1.train.NewCheckpointReader(TF_CKPT_DIR)\n",
    "model.set_weights([ckpt_reader.get_tensor(v.name[:-2]) for v in tqdm(model.trainable_weights, position=0)])\n",
    "\n",
    "hf_model.load_state_dict(torch.load(HF_CKPT_DIR))\n",
    "hf_model.eval()\n",
    "\"model weights loaded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:**** Using original full attention ****\n",
      "INFO:absl:**** Using original full attention ****\n",
      "INFO:absl:**** Using original full attention ****\n",
      "INFO:absl:**** Using original full attention ****\n",
      "INFO:absl:**** Using original full attention ****\n",
      "INFO:absl:**** Using original full attention ****\n",
      "INFO:absl:**** Using original full attention ****\n",
      "INFO:absl:**** Using original full attention ****\n",
      "INFO:absl:**** Using original full attention ****\n",
      "INFO:absl:**** Using original full attention ****\n",
      "INFO:absl:**** Using original full attention ****\n",
      "INFO:absl:**** Using original full attention ****\n"
     ]
    }
   ],
   "source": [
    "sequence_output, pooler_output = model(input_ids, training=False)\n",
    "_ = hf_model(hf_input_ids)\n",
    "hf_sequence_output = hf_model.sequence_output\n",
    "hf_pooler_output = hf_model.pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 128, 768) torch.Size([2, 128, 768]) (2, 768) torch.Size([2, 768])\n"
     ]
    }
   ],
   "source": [
    "print(sequence_output.shape, hf_sequence_output.shape, pooler_output.shape, hf_pooler_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"model input_ids\", model.input_ids, end=\"\\n\\n\")\n",
    "# print(\"embeddding\", model.word_embeddings, end=\"\\n\\n\")\n",
    "\n",
    "# print(\"l1 layer_input\", model.encoder.l1_layer_input, end=\"\\n\\n\")\n",
    "# print(\"l1 attn_mask\", model.encoder.l1_attention_mask, end=\"\\n\\n\")\n",
    "# print(\"l1 encoder_from_mask\", model.encoder.l1_encoder_from_mask, end=\"\\n\\n\")\n",
    "# print(\"l1 encoder_to_mask\", model.encoder.l1_encoder_to_mask, end=\"\\n\\n\")\n",
    "# print(\"l1 blocked_encoder_mask\", model.encoder.l1_blocked_encoder_mask, end=\"\\n\\n\")\n",
    "# print(\"l1_training\", model.encoder.l1_training, end=\"\\n\\n\")\n",
    "\n",
    "# print(\"l1 layer_output\", model.encoder.l1_layer_output, end=\"\\n\\n\")\n",
    "# print(\"last layer_output\", model.encoder.last_layer_output, end=\"\\n\\n\")\n",
    "\n",
    "# print(\"bigbird sequence out\", sequence_output, end=\"\\n\\n\")\n",
    "# print(\"bigbird pooler output\", pooled_output, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_between_tensors(tf_tensor, pt_tensor):\n",
    "    tf_np = np.array(tf_tensor)\n",
    "    pt_np = np.array(pt_tensor.detach())\n",
    "    return np.max(np.abs(tf_np - pt_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RUN THIS FOR WEIGHTS CONVERSION\n",
    "\n",
    "# from transformers import BigBirdForPreTraining, BigBirdConfig, load_tf_weights_in_big_bird\n",
    "\n",
    "# config = BigBirdConfig()\n",
    "# model = BigBirdForPreTraining(config)\n",
    "\n",
    "# old = model.state_dict()\n",
    "\n",
    "# model = load_tf_weights_in_big_bird(model, \"ckpt/bigbr_base/model.ckpt-0\")\n",
    "\n",
    "# model.save_pretrained(\"google/bigbird-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difference bw input_ids: 0\n",
      "difference bw word_embeddings: 0.0\n",
      "difference bw l1 layer_input 7.1525574e-07\n",
      "difference bw l1 layer_output 5.2452087e-06\n",
      "difference bw last layer_output 1.2040138e-05\n",
      "difference bw bigbird sequence out 1.2040138e-05\n",
      "\n",
      "difference bw bigbird pooler output 1.758337e-06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"difference bw input_ids:\", difference_between_tensors(model.input_ids, hf_model.bert.input_ids))\n",
    "print(\"difference bw word_embeddings:\", difference_between_tensors(model.word_embeddings, hf_model.bert.word_embeddings))\n",
    "\n",
    "print(\"difference bw l1 layer_input\", difference_between_tensors(model.encoder.l1_layer_input, hf_model.bert.encoder.l1_layer_input))\n",
    "\n",
    "print(\"difference bw l1 layer_output\", difference_between_tensors(model.encoder.l1_layer_output, hf_model.bert.encoder.l1_layer_output))\n",
    "print(\"difference bw last layer_output\", difference_between_tensors(model.encoder.last_layer_output,hf_model.bert.encoder.last_layer_output))\n",
    "\n",
    "print(\"difference bw bigbird sequence out\", difference_between_tensors(sequence_output, hf_sequence_output), end=\"\\n\\n\")\n",
    "\n",
    "print(\"difference bw bigbird pooler output\", difference_between_tensors(pooler_output, hf_pooler_output), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.train.list_variables(\"ckpt/bigbr_base/model.ckpt-0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers.models.big_bird.modeling_big_bird import BigBirdAttention\n",
    "# from bigbird.core.attention import MultiHeadedAttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # layer-0 debugging\n",
    "\n",
    "# print(\"difference bw k:\", difference_between_tensors(model.encoder.encoder_layers[0].attn_layer.k, hf_model.bert.encoder.layer[0].attention.self.k\n",
    "# ))\n",
    "\n",
    "# print(\"difference bw q:\", difference_between_tensors(model.encoder.encoder_layers[0].attn_layer.q, hf_model.bert.encoder.layer[0].attention.self.q\n",
    "# ))\n",
    "\n",
    "# print(\"difference bw v:\", difference_between_tensors(model.encoder.encoder_layers[0].attn_layer.v, hf_model.bert.encoder.layer[0].attention.self.v\n",
    "# ))\n",
    "\n",
    "# print(\"difference bw v:\", difference_between_tensors(model.encoder.encoder_layers[0].attn_layer.v, hf_model.bert.encoder.layer[0].attention.self.v\n",
    "# ))\n",
    "\n",
    "# print(\"difference bw attn_sc:\", difference_between_tensors(model.encoder.encoder_layers[0].attn_layer.attn_sc, hf_model.bert.encoder.layer[0].attention.self.attn_sc\n",
    "# ))\n",
    "\n",
    "# print(\"difference bw attn_p:\", difference_between_tensors(model.encoder.encoder_layers[0].attn_layer.attn_p, hf_model.bert.encoder.layer[0].attention.self.attn_p\n",
    "# ))\n",
    "\n",
    "\n",
    "# print(\"difference bw attn_o:\", difference_between_tensors(model.encoder.encoder_layers[0].attn_layer.attn_o, hf_model.bert.encoder.layer[0].attention.self.attn_o\n",
    "# ))\n",
    "\n",
    "# print(\"difference bw attn_proj_o:\", difference_between_tensors(model.encoder.encoder_layers[0].attn_proj_o, hf_model.bert.encoder.layer[0].attn_proj_o\n",
    "# ))\n",
    "\n",
    "# print(\"difference bw int_o:\", difference_between_tensors(model.encoder.encoder_layers[0].int_o, hf_model.bert.encoder.layer[0].int_o\n",
    "# ))\n",
    "\n",
    "# print(\"difference bw io:\", difference_between_tensors(model.encoder.encoder_layers[0].io, hf_model.bert.encoder.layer[0].output.io\n",
    "# ))\n",
    "\n",
    "# print(\"difference bw o:\", difference_between_tensors(model.encoder.encoder_layers[0].o, hf_model.bert.encoder.layer[0].output.o\n",
    "# ))\n",
    "\n",
    "# print(\"difference bw do:\", difference_between_tensors(model.encoder.encoder_layers[0].do, hf_model.bert.encoder.layer[0].output.do\n",
    "# ))\n",
    "\n",
    "# print(\"difference bw l_o:\", difference_between_tensors(model.encoder.encoder_layers[0].l_o, hf_model.bert.encoder.layer[0].l_o\n",
    "# ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"difference bw hs:\", difference_between_tensors(model.encoder.encoder_layers[0].attn_layer.hs, hf_model.bert.encoder.layer[0].attention.self.hs))\n",
    "# print(\"difference bw bm:\", difference_between_tensors(model.encoder.encoder_layers[0].attn_layer.bm, hf_model.bert.encoder.layer[0].attention.self.bm))                                                     \n",
    "# print(\"difference bw fm:\", difference_between_tensors(model.encoder.encoder_layers[0].attn_layer.fm, hf_model.bert.encoder.layer[0].attention.self.fm))\n",
    "# print(\"difference bw tm:\", difference_between_tensors(model.encoder.encoder_layers[0].attn_layer.tm, hf_model.bert.encoder.layer[0].attention.self.tm))\n",
    "# print(\"difference bw fbm:\", difference_between_tensors(model.encoder.encoder_layers[0].attn_layer.fbm, hf_model.bert.encoder.layer[0].attention.self.fbm))\n",
    "# print(\"difference bw tbm:\", difference_between_tensors(model.encoder.encoder_layers[0].attn_layer.tbm, hf_model.bert.encoder.layer[0].attention.self.tbm))\n",
    "\n",
    "# print(\"difference bw ran:\", difference_between_tensors(model.encoder.encoder_layers[0].attn_layer.ran, hf_model.bert.encoder.layer[0].attention.self.ran))\n",
    "\n",
    "# print(\"difference bw rand_mask:\", difference_between_tensors(model.encoder.encoder_layers[0].attn_layer.rand_mask, hf_model.bert.encoder.layer[0].attention.self.rand_mask))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"difference bw gk:\", difference_between_tensors(model.encoder.encoder_layers[0].attn_layer.gk, hf_model.bert.encoder.layer[0].attention.self.gk))\n",
    "# print(\"difference bw gv:\", difference_between_tensors(model.encoder.encoder_layers[0].attn_layer.gv, hf_model.bert.encoder.layer[0].attention.self.gv))\n",
    "\n",
    "# print(\"difference bw fcl:\", difference_between_tensors(model.encoder.encoder_layers[0].attn_layer.fcl, hf_model.bert.encoder.layer[0].attention.self.fcl))\n",
    "\n",
    "# print(\"difference bw fcl:\", difference_between_tensors(model.encoder.encoder_layers[0].attn_layer.scl, hf_model.bert.encoder.layer[0].attention.self.scl))\n",
    "# print(\"difference bw cl:\", difference_between_tensors(model.encoder.encoder_layers[0].attn_layer.cl, hf_model.bert.encoder.layer[0].attention.self.cl))\n",
    "\n",
    "# print(\"difference bw slcl:\", difference_between_tensors(model.encoder.encoder_layers[0].attn_layer.cl, hf_model.bert.encoder.layer[0].attention.self.slcl))\n",
    "\n",
    "\n",
    "# print(\"difference bw final_cl:\", difference_between_tensors(model.encoder.encoder_layers[0].attn_layer.final_cl, hf_model.bert.encoder.layer[0].attention.self.final_cl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacement of tf.gather in torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def torch_gather_b2(params, indices):\n",
    "#     batch_dims = 2\n",
    "#     assert params.shape[:batch_dims] == indices.shape[:batch_dims]\n",
    "#     out_shape = indices.shape + params.shape[-1:]\n",
    "\n",
    "#     out = torch.stack(\n",
    "#         [torch.stack(\n",
    "#             [p2[i2.flatten()] for p2, i2 in zip(p1, i1)]\n",
    "#         ) for p1, i1 in zip(params, indices)]\n",
    "#     )\n",
    "#     return out.view(out_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import torch\n",
    "# import numpy as np\n",
    "\n",
    "# np.random.seed(0)\n",
    "\n",
    "# params = np.random.randn(2, 12, 256, 16)\n",
    "# indices = np.random.randint(2, dtype=np.int32, size=(2, 12, 254, 3))\n",
    "\n",
    "# tf_p = tf.convert_to_tensor(params)\n",
    "# tf_i = tf.convert_to_tensor(indices)\n",
    "\n",
    "# py_p = torch.from_numpy(params)\n",
    "# py_i = torch.from_numpy(indices).long()\n",
    "\n",
    "# # output.shape = params.shape[:axis] + indices.shape[batch_dims:] + params.shape[axis + 1:]\n",
    "\n",
    "# out_tf = tf.gather(tf_p, tf_i, batch_dims=2)\n",
    "# out_pt = torch_gather_b2(py_p, py_i)\n",
    "# out_tf = tf.gather(tf_p, tf_i, batch_dims=1)\n",
    "# params = py_p\n",
    "# indices = py_i\n",
    "# out_pt = torch.stack([p1[i1.flatten()] for p1, i1 in zip(params, indices)]).view(indices.shape + params.shape[-2:])\n",
    "# np.max(np.abs(out_pt.numpy() - out_tf.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
